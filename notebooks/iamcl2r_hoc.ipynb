{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.models as models\n",
    "\n",
    "from continuum.datasets import CIFAR100\n",
    "from continuum import ClassIncremental\n",
    "from continuum.rehearsal import RehearsalMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose the number of tasks you want to perform\n",
    "# ntasks = 31\n",
    "ntasks = 7\n",
    "\n",
    "checkpoint_path = f'./output/hoc_{ntasks}tasks'  # where to store model checkpoints\n",
    "\n",
    "if ntasks == 7:\n",
    "  increment = 15                # classes in each subsequent task\n",
    "  replace_ids = [0, 2, 4]       # task id in which model replacements occur (0 means start with a pretrained model)\n",
    "elif ntasks == 31:\n",
    "  increment = 3                # classes in each subsequent task\n",
    "  replace_ids = [0, 10, 20]       # task id in which model replacements occur (0 means start with a pretrained model)\n",
    "else:\n",
    "  raise NotImplementedError(f'ntasks={ntasks} not implemented')\n",
    "\n",
    "epochs = 70\n",
    "batch_size = 128\n",
    "img_per_class = 300           # reduce cifar100 to have 300 images per class (instead of the original 500)\n",
    "initial_increment  = 10       # classes in the initial task\n",
    "rehearsal = 20                # number of images per class stored in the episodic memory for rehearsal\n",
    "amp = True                    # automatic mixed precision\n",
    "\n",
    "pretrained_model_path = ['../pretrained_models_ckpts/simplex/ckpt_0.pt',  # resnet18 trained on 100 imagenet32 classes\n",
    "                         '../pretrained_models_ckpts/simplex/ckpt_1.pt',  # resnet18 trained on 300 imagenet32 classes\n",
    "                         '../pretrained_models_ckpts/simplex/ckpt_2.pt'   # resnet18 trained on 600 imagenet32 classes\n",
    "                        ]\n",
    "\n",
    "# reproducibility\n",
    "seed = 42\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOC loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOC hyperparams\n",
    "preallocated_classes = 1024\n",
    "feat_size = 1023\n",
    "mu_ = 10\n",
    "lambda_ = 0.1\n",
    "\n",
    "class HocLoss(nn.Module):\n",
    "  def __init__(self, mu_ = 10):\n",
    "    super(HocLoss, self).__init__()\n",
    "    self.mu_ = mu_\n",
    "\n",
    "  def forward(self,\n",
    "          feat_new,\n",
    "          feat_old,\n",
    "          labels,\n",
    "          ):\n",
    "    loss = self._loss(feat_old, feat_new, labels)\n",
    "    return loss\n",
    "\n",
    "  def _loss(self, out0, out1, labels):\n",
    "    \"\"\"Calculates infoNCE loss.\n",
    "    This code implements Equation 4 in \"Stationary Representations: Optimally Approximating Compatibility and Implications for Improved Model Replacements\"\n",
    "\n",
    "    Args:\n",
    "        feat_old:\n",
    "            features extracted with the old model.\n",
    "            Shape: (batch_size, embedding_size)\n",
    "        feat_new:\n",
    "            features extracted with the new model.\n",
    "            Shape: (batch_size, embedding_size)\n",
    "        labels:\n",
    "            Labels of the images.\n",
    "            Shape: (batch_size,)\n",
    "    Returns:\n",
    "        Mean loss over the mini-batch.\n",
    "    \"\"\"\n",
    "    batch_size = out0.shape[0]\n",
    "    diag_mask = torch.eye(batch_size, device=out0.device, dtype=torch.bool)\n",
    "    sim_01 = torch.einsum(\"nc,mc->nm\", out0, out1) *  self.mu_\n",
    "\n",
    "    positive_loss = -sim_01[diag_mask]\n",
    "    labels_0 = labels.unsqueeze(1).expand(-1, batch_size)  # Shape: (batch_size, batch_size)\n",
    "    labels_1 = labels.unsqueeze(0).expand(batch_size, -1)  # Shape: (batch_size, batch_size)\n",
    "\n",
    "    class_mask = labels_0 == labels_1\n",
    "    sim_01 = (sim_01* (~class_mask)).view(batch_size, -1)\n",
    "\n",
    "    negative_loss_01 = torch.logsumexp(sim_01, dim=1)\n",
    "    return (positive_loss + negative_loss_01).mean()\n",
    "\n",
    "hoc_loss = HocLoss(mu_)\n",
    "# local classes are written from the bottom of the shared interface w the server\n",
    "target_transform = transforms.Lambda(lambda y: preallocated_classes - 1 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model\n",
    "class dSimplex_ResNet(nn.Module):\n",
    "  def __init__(self,\n",
    "               num_classes,\n",
    "               feat_size\n",
    "              ):\n",
    "    super(dSimplex_ResNet, self).__init__()\n",
    "    backbone = models.resnet18()\n",
    "    backbone.fc = nn.Identity()\n",
    "    self.backbone = backbone\n",
    "    self.fc1 = nn.Linear(512, feat_size, bias=False)          # junction layer\n",
    "    self.fc2 = nn.Linear(feat_size, num_classes, bias=False)  # classifier\n",
    "    self.fc2.weight.requires_grad = False                     # set no gradient for the fixed classifier\n",
    "    self.fc2.weight.copy_(self.dsimplex(num_classes))         # set the weights for the classifier\n",
    "\n",
    "  def dsimplex(self, num_classes, device='cuda'):\n",
    "    def simplex_coordinates_gpu(n, device):\n",
    "      t = torch.zeros((n + 1, n), device=device)\n",
    "      torch.eye(n, out=t[:-1,:], device=device)\n",
    "      val = (1.0 - torch.sqrt(1.0 + torch.tensor([n], device=device))) / n\n",
    "      t[-1,:].add_(val)\n",
    "      t.add_(-torch.mean(t, dim=0))\n",
    "      t.div_(torch.norm(t, p=2, dim=1, keepdim=True)+ 1e-8)\n",
    "      return t\n",
    "\n",
    "    feat_size = num_classes - 1\n",
    "    return simplex_coordinates_gpu(feat_size, device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.backbone(x)\n",
    "    z = self.fc1(x)\n",
    "    y = self.fc2(z)\n",
    "    return {'logits': y, 'features': z}\n",
    "\n",
    "  def resume_weights(self, resume_path):\n",
    "    print(f\"Resuming Weights from {resume_path}\")\n",
    "    new_pretrained_dict = torch.load(resume_path, map_location='cpu')\n",
    "    if \"net\" in new_pretrained_dict.keys():\n",
    "      new_pretrained_dict = new_pretrained_dict[\"net\"]\n",
    "\n",
    "    if \"pretrained\" in resume_path:\n",
    "      state_dict = OrderedDict()\n",
    "      for k, v in new_pretrained_dict.items():\n",
    "        name = k.replace('.blocks.', '.')\n",
    "        if name not in self.state_dict().keys():\n",
    "          continue\n",
    "        state_dict[name] = v\n",
    "      del state_dict['fc2.weight'] # remove classifier weights from iamcl2r pretrained weights\n",
    "    else:\n",
    "      state_dict = new_pretrained_dict\n",
    "\n",
    "    self.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## dataset\n",
    "train_transform = [transforms.Resize((32, 32)),\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                                        (0.2675, 0.2565, 0.2761))\n",
    "                    ]\n",
    "val_transform = [transforms.Resize((32, 32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                                    (0.2675, 0.2565, 0.2761))\n",
    "                ]\n",
    "\n",
    "# training task-sets for sequential fine-tuning learning\n",
    "scenario_train = ClassIncremental(CIFAR100(data_path='../data', train=True, download=True),\n",
    "                                  initial_increment=initial_increment,\n",
    "                                  increment=increment,\n",
    "                                  transformations=train_transform\n",
    "                                  )\n",
    "num_classes = scenario_train.nb_classes\n",
    "nb_tasks = scenario_train.nb_tasks\n",
    "\n",
    "# episodic memory for rehearsal\n",
    "memory = RehearsalMemory(memory_size=num_classes * rehearsal,\n",
    "                          herding_method=\"random\",\n",
    "                          fixed_memory=True,\n",
    "                          nb_total_classes=num_classes\n",
    "                        )\n",
    "\n",
    "# validation task-sets for sequential fine-tuning learning\n",
    "scenario_val = ClassIncremental(CIFAR100(data_path='../data', train=False, download=True),\n",
    "                                initial_increment=initial_increment,\n",
    "                                increment=increment,\n",
    "                                transformations=val_transform\n",
    "                                )\n",
    "\n",
    "\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "  def __init__(self, dataset, batch_size, n_classes, n_samples, seen_classes, rehearsal=0):\n",
    "    self.dataset = dataset\n",
    "    self.batch_size = batch_size\n",
    "    self.n_classes = n_classes\n",
    "    self.n_samples = n_samples\n",
    "    self.seen_classes = seen_classes\n",
    "    self.rehearsal = rehearsal\n",
    "    self.n_batches = self.n_samples // self.batch_size # drop last\n",
    "    if self.n_batches == 0:\n",
    "      self.n_batches = 1\n",
    "      self.size = self.n_samples if rehearsal == 0 else self.n_samples//2\n",
    "    elif rehearsal == 0:\n",
    "      self.size = self.batch_size\n",
    "    else:\n",
    "      self.size = self.batch_size//2\n",
    "    self.index_dic = dd(list)\n",
    "    self.indices = []\n",
    "    self.seen_indices = []\n",
    "    for index, y in enumerate(self.dataset._y):\n",
    "      if y not in self.seen_classes:\n",
    "        self.indices.append(index)\n",
    "      else:\n",
    "        self.seen_indices.append(index)\n",
    "\n",
    "  def __iter__(self):\n",
    "    for _ in range(self.n_batches):\n",
    "      batch = []\n",
    "      if self.rehearsal > 0:\n",
    "        replace = True if len(self.seen_indices) <= self.size else False\n",
    "        batch.extend(np.random.choice(self.seen_indices, size=self.size, replace=replace))\n",
    "      replace = True if len(self.indices) <= self.size else False\n",
    "      batch.extend(np.random.choice(self.indices, size=self.size, replace=replace))\n",
    "      yield batch\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{IAM-CL}^2\\text{R}$  Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 new classes in task: [0 1 2 3 4 5 6 7 8 9]\n",
      "Resuming Weights from ../pretrained_models_ckpts/simplex/ckpt_0.pt\n",
      "Resuming Weights from ../pretrained_models_ckpts/simplex/ckpt_0.pt\n",
      "Task 2 new classes in task: [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Task 3 new classes in task: [25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "Resuming Weights from ../pretrained_models_ckpts/simplex/ckpt_1.pt\n",
      "Resuming Weights from ../pretrained_models_ckpts/simplex/ckpt_1.pt\n",
      "Task 4 new classes in task: [40 41 42 43 44 45 46 47 48 49 50 51 52 53 54]\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Task 5 new classes in task: [55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]\n",
      "Resuming Weights from ../pretrained_models_ckpts/simplex/ckpt_2.pt\n",
      "Resuming Weights from ../pretrained_models_ckpts/simplex/ckpt_2.pt\n",
      "Task 6 new classes in task: [70 71 72 73 74 75 76 77 78 79 80 81 82 83 84]\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_4.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_4.pt\n",
      "Task 7 new classes in task: [85 86 87 88 89 90 91 92 93 94 95 96 97 98 99]\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_5.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_5.pt\n",
      "Starting Epoch 70/70 at task 7/7\r"
     ]
    }
   ],
   "source": [
    "classes_at_task = []\n",
    "seen_classes = []\n",
    "\n",
    "for task_id, (train_task_set, _) in enumerate(zip(scenario_train, scenario_val)):\n",
    "  if task_id in replace_ids:\n",
    "    resume_path = pretrained_model_path[replace_ids.index(task_id)]\n",
    "  else:\n",
    "    resume_path = osp.join(*(checkpoint_path, f\"ckpt_{task_id-1}.pt\"))\n",
    "\n",
    "  new_data_ids = train_task_set.get_classes()\n",
    "  val_dataset = scenario_val[:task_id + 1]\n",
    "\n",
    "  class_in_step = scenario_train[:task_id].nb_classes + len(new_data_ids) if task_id > 0 else train_task_set.nb_classes\n",
    "  classes_at_task.append(class_in_step)\n",
    "\n",
    "  print(f\"Task {task_id+1} new classes in task: {new_data_ids}\")\n",
    "\n",
    "  previous_net = dSimplex_ResNet(num_classes=preallocated_classes, feat_size=feat_size)\n",
    "  previous_net.resume_weights(resume_path=resume_path)\n",
    "  # set false to require grad for all parameters\n",
    "  for param in previous_net.parameters():\n",
    "      param.requires_grad = False\n",
    "  previous_net.eval()\n",
    "  previous_net.cuda()\n",
    "\n",
    "  net = dSimplex_ResNet(num_classes=preallocated_classes, feat_size=feat_size)\n",
    "  net.resume_weights(resume_path=resume_path)\n",
    "  net.train()\n",
    "  net.cuda()\n",
    "\n",
    "  criterion_cls = nn.CrossEntropyLoss().cuda()\n",
    "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-04)\n",
    "  scheduler_lr = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.00001)\n",
    "\n",
    "  batchsampler = None\n",
    "  if task_id > 0:\n",
    "      mem_x, mem_y, mem_t = memory.get()\n",
    "      train_task_set.add_samples(mem_x, mem_y, mem_t)\n",
    "      batchsampler = BalancedBatchSampler(train_task_set, n_classes=train_task_set.nb_classes,\n",
    "                                          batch_size=batch_size, n_samples=len(train_task_set._x),\n",
    "                                          seen_classes=seen_classes, rehearsal=rehearsal)\n",
    "      train_loader = DataLoader(train_task_set, batch_sampler=batchsampler,\n",
    "                                num_workers=4)\n",
    "  else:\n",
    "      train_loader = DataLoader(train_task_set, batch_size=batch_size, shuffle=True,\n",
    "                                drop_last=True, num_workers=4)\n",
    "\n",
    "  val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=batch_size, shuffle=False,\n",
    "                          drop_last=False, num_workers=4)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    print(f\"Starting Epoch {epoch+1}/{epochs} at task {task_id+1}/{nb_tasks}\", end=\"\\r\")\n",
    "    for batchdata in train_loader:\n",
    "      inputs = batchdata[0].cuda()\n",
    "      targets = batchdata[1].cuda()\n",
    "\n",
    "      # transform targets to write for the end of the feature vector\n",
    "      targets = target_transform(targets)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      output = net(inputs)\n",
    "      loss = criterion_cls(output[\"logits\"], targets)\n",
    "      with torch.no_grad():\n",
    "        feature_old = previous_net(inputs)[\"features\"]\n",
    "\n",
    "      loss_feat = hoc_loss(F.normalize(output[\"features\"], dim=1),\n",
    "                          F.normalize(feature_old, dim=1),\n",
    "                          targets\n",
    "                          )\n",
    "      loss = loss * lambda_ + (1 - lambda_) * loss_feat  # Eq. 3 in the paper\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    scheduler_lr.step()\n",
    "\n",
    "  # save model checkpoint after task\n",
    "  if not osp.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "  torch.save(net.state_dict(), osp.join(checkpoint_path, f'ckpt_{task_id}.pt'))\n",
    "\n",
    "  # add sample in the episodic memory\n",
    "  memory.add(*scenario_train[task_id].get_raw_samples(), z=None)\n",
    "  seen_classes = torch.tensor(list(memory.seen_classes), device='cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metric\n",
    "def calculate_mAP_gldv2(ranked_gallery_indices, query_gts, topk):\n",
    "  num_q = ranked_gallery_indices.shape[0]\n",
    "  average_precision = np.zeros(num_q, dtype=float)\n",
    "  for i in range(num_q):\n",
    "    retrieved_indices = np.where(np.in1d(ranked_gallery_indices[i], np.array(query_gts[i])))[0]\n",
    "    if retrieved_indices.shape[0] > 0:\n",
    "      retrieved_indices = np.sort(retrieved_indices)\n",
    "      gts_all_count = min(len(query_gts[i]), topk)\n",
    "      for j, index in enumerate(retrieved_indices):\n",
    "        average_precision[i] += (j + 1) * 1.0 / (index + 1)\n",
    "      average_precision[i] /= gts_all_count\n",
    "  return np.mean(average_precision)\n",
    "\n",
    "\n",
    "def image2template_feature(img_feats=None,  # features of all images\n",
    "                           templates=None,  # target of features in input\n",
    "                          ):\n",
    "\n",
    "  unique_templates = np.unique(templates)\n",
    "  unique_subjectids = None\n",
    "\n",
    "  template_feats = np.zeros((len(unique_templates), img_feats.shape[1]))\n",
    "\n",
    "  for count_template, uqt in enumerate(unique_templates):\n",
    "    ind_t = np.where(templates == uqt)[0]\n",
    "    face_norm_feats = img_feats[ind_t]\n",
    "    template_feats[count_template] = np.mean(face_norm_feats, 0)\n",
    "\n",
    "  template_norm_feats = template_feats / np.sqrt(\n",
    "      np.sum(template_feats ** 2, -1, keepdims=True))\n",
    "  return template_norm_feats, unique_templates, unique_subjectids\n",
    "\n",
    "\n",
    "def calculate_rank(query_feats, gallery_feats, topk):\n",
    "  num_q, feat_dim = query_feats.shape\n",
    "  faiss_index = faiss.IndexFlatIP(feat_dim)\n",
    "  faiss_index.add(gallery_feats)\n",
    "  _, ranked_gallery_indices = faiss_index.search(query_feats, topk)\n",
    "  return ranked_gallery_indices\n",
    "\n",
    "\n",
    "def identification(gallery_feats, gallery_gts, query_feats, query_gts, topk=1):\n",
    "  # https://github.com/TencentARC/OpenCompatible/blob/master/data_loader/GLDv2.py#L129\n",
    "  query_gts = np.array(query_gts).reshape(-1, 1)\n",
    "  unique_gallery_feats, _, _ = image2template_feature(gallery_feats, gallery_gts)\n",
    "  unique_gallery_feats = unique_gallery_feats.astype(np.float32)\n",
    "\n",
    "  ranked_gallery_indices = calculate_rank(query_feats, unique_gallery_feats, topk=1)\n",
    "  mAP = calculate_mAP_gldv2(ranked_gallery_indices, query_gts, topk=1)\n",
    "  return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compatibility metrics\n",
    "def create_position_matrix(matrix=None, **kwargs):\n",
    "  position = np.zeros_like(matrix, dtype=bool)\n",
    "  for j in range(matrix.shape[0]):\n",
    "    for i in range(j + 1, matrix.shape[1]):\n",
    "      if matrix[i][j] <= matrix[j][j]:\n",
    "        position[i, j] = True\n",
    "  return position\n",
    "\n",
    "def average_compatibility(matrix=None, position=None, **kwargs):\n",
    "  steps = matrix.shape[0]\n",
    "  if position is None:\n",
    "    position = create_position_matrix(matrix)\n",
    "  max_ac = (steps * (steps-1)) / 2\n",
    "  if max_ac < 1:\n",
    "    max_ac = 1\n",
    "  ac = max_ac - np.sum(position)\n",
    "  return (1/max_ac) * ac\n",
    "\n",
    "def replace_zero_with_nan(matrix, **kwargs):\n",
    "  idx = np.where(matrix == 0)\n",
    "  matrix[idx] = np.nan\n",
    "  return matrix\n",
    "\n",
    "def average_accuracy(matrix=None, per_task=False, **kwargs):\n",
    "  if max(matrix[-1]) < 1:\n",
    "    matrix = matrix * 100\n",
    "  copy_matrix = matrix.copy()\n",
    "  values = [np.nanmean(replace_zero_with_nan(copy_matrix)[:i+1,:i+1]) for i in range(copy_matrix.shape[0])]\n",
    "\n",
    "  if per_task:\n",
    "    return values\n",
    "  else:\n",
    "    return values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# query and gallery loader\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                                                        (0.2675, 0.2565, 0.2761))\n",
    "                                    ])\n",
    "gallery_set = CIFAR10(root='../data', train=False, download=True,\n",
    "                      transform=transform)\n",
    "gallery_loader = DataLoader(gallery_set, batch_size=batch_size, shuffle=False,\n",
    "                            drop_last=False, num_workers=4)\n",
    "\n",
    "query_set = CIFAR10(root='../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "query_loader = DataLoader(query_set, batch_size=batch_size, shuffle=False,\n",
    "                          drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(net, loader):\n",
    "  features = None\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for inputs in loader:\n",
    "      images = inputs[0].cuda()\n",
    "      f = net(images)['features']\n",
    "      f = F.normalize(f, dim=1)\n",
    "      features = torch.cat((features, f), 0) if features is not None else f\n",
    "  return features.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Self-test of model at task 1 1:N search acc: 0.59\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Cross-test between models at task 2 and 1 1:N search acc: 0.60\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Self-test of model at task 2 1:N search acc: 0.62\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Cross-test between models at task 3 and 1 1:N search acc: 0.63\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Cross-test between models at task 3 and 2 1:N search acc: 0.65\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Self-test of model at task 3 1:N search acc: 0.69\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_3.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Cross-test between models at task 4 and 1 1:N search acc: 0.63\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Cross-test between models at task 4 and 2 1:N search acc: 0.65\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Cross-test between models at task 4 and 3 1:N search acc: 0.71\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_3.pt\n",
      "Self-test of model at task 4 1:N search acc: 0.72\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_4.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Cross-test between models at task 5 and 1 1:N search acc: 0.65\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Cross-test between models at task 5 and 2 1:N search acc: 0.68\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Cross-test between models at task 5 and 3 1:N search acc: 0.71\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_3.pt\n",
      "Cross-test between models at task 5 and 4 1:N search acc: 0.72\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_4.pt\n",
      "Self-test of model at task 5 1:N search acc: 0.74\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_5.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Cross-test between models at task 6 and 1 1:N search acc: 0.64\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Cross-test between models at task 6 and 2 1:N search acc: 0.67\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Cross-test between models at task 6 and 3 1:N search acc: 0.71\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_3.pt\n",
      "Cross-test between models at task 6 and 4 1:N search acc: 0.73\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_4.pt\n",
      "Cross-test between models at task 6 and 5 1:N search acc: 0.75\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_5.pt\n",
      "Self-test of model at task 6 1:N search acc: 0.76\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_6.pt\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_0.pt\n",
      "Cross-test between models at task 7 and 1 1:N search acc: 0.63\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_1.pt\n",
      "Cross-test between models at task 7 and 2 1:N search acc: 0.66\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_2.pt\n",
      "Cross-test between models at task 7 and 3 1:N search acc: 0.72\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_3.pt\n",
      "Cross-test between models at task 7 and 4 1:N search acc: 0.73\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_4.pt\n",
      "Cross-test between models at task 7 and 5 1:N search acc: 0.75\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_5.pt\n",
      "Cross-test between models at task 7 and 6 1:N search acc: 0.77\n",
      "Resuming Weights from ./output/hoc_7tasks_amp/ckpt_6.pt\n",
      "Self-test of model at task 7 1:N search acc: 0.77\n",
      "Compatibility Matrix:\n",
      "[[0.58892 0.      0.      0.      0.      0.      0.     ]\n",
      " [0.597   0.6156  0.      0.      0.      0.      0.     ]\n",
      " [0.6305  0.65276 0.69314 0.      0.      0.      0.     ]\n",
      " [0.63336 0.65298 0.70626 0.72374 0.      0.      0.     ]\n",
      " [0.65006 0.67872 0.70754 0.72114 0.73828 0.      0.     ]\n",
      " [0.6408  0.67188 0.71166 0.72712 0.74704 0.76194 0.     ]\n",
      " [0.6314  0.6635  0.72096 0.73496 0.75232 0.76652 0.77164]]\n",
      "AC = 0.95\n",
      "AM = 68.899\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "compatibility_matrix = np.zeros((nb_tasks, nb_tasks))\n",
    "query_targets = query_loader.dataset.targets\n",
    "gallery_targets = gallery_loader.dataset.targets\n",
    "\n",
    "previous_net = dSimplex_ResNet(num_classes=preallocated_classes, feat_size=feat_size)\n",
    "net = dSimplex_ResNet(num_classes=preallocated_classes, feat_size=feat_size)\n",
    "\n",
    "for task_id in range(nb_tasks):\n",
    "  ckpt_path = osp.join(*(checkpoint_path, f\"ckpt_{task_id}.pt\"))\n",
    "  net.resume_weights(resume_path=ckpt_path)\n",
    "  net.eval()\n",
    "  net.cuda()\n",
    "\n",
    "  query_feat = extract_features(net, query_loader)\n",
    "\n",
    "  for i in range(task_id+1):\n",
    "      ckpt_path = osp.join(*(checkpoint_path, f\"ckpt_{i}.pt\"))\n",
    "      previous_net.resume_weights(resume_path=ckpt_path)\n",
    "      previous_net.eval()\n",
    "      previous_net.cuda()\n",
    "\n",
    "      gallery_feat = extract_features(previous_net, gallery_loader)\n",
    "\n",
    "      acc = identification(gallery_feat, gallery_targets,\n",
    "                           query_feat, query_targets,\n",
    "                           topk=1\n",
    "                          )\n",
    "\n",
    "      compatibility_matrix[task_id][i] = acc\n",
    "      if i != task_id:\n",
    "          acc_str = f'Cross-test between models at task {task_id+1} and {i+1}'\n",
    "      else:\n",
    "          acc_str = f'Self-test of model at task {i+1}'\n",
    "      print(f'{acc_str} 1:N search acc: {acc:.2f}')\n",
    "\n",
    "print(f\"Compatibility Matrix:\\n{compatibility_matrix}\")\n",
    "\n",
    "if compatibility_matrix.shape[0] > 1:\n",
    "  ac = average_compatibility(matrix=compatibility_matrix)\n",
    "  am = average_accuracy(matrix=compatibility_matrix)\n",
    "\n",
    "  print(f\"AC = {ac:.2f}\")\n",
    "  print(f\"AM = {am:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot AM per task\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'text.latex.preamble': r'\\usepackage{amsfonts}'\n",
    "})\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "\n",
    "values = average_accuracy(matrix=compatibility_matrix, per_task=True)\n",
    "ntasks = compatibility_matrix.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "replacemenet_ids = replace_ids[1:]\n",
    "for idx in replacemenet_ids:\n",
    "  plt.axvline(x=idx+1, color='#DDDDDD', linestyle='solid', lw=1.5, zorder=-5)\n",
    "plt.grid(axis='y', color='#DDDDDD', linestyle='solid', lw=1.5, zorder=-5)\n",
    "x = np.arange(1, ntasks+1)\n",
    "\n",
    "face_colors = ['white' if not i in replacemenet_ids else 'yellow' for i in range(len(x))]\n",
    "cols = ['#D92929' if not i in replacemenet_ids else 'red' for i in range(len(x))]\n",
    "sizes = [150 if i in replacemenet_ids else 50 for i in range(len(x))]\n",
    "\n",
    "plt.plot(x, values,  color='#D92929', linestyle='solid', lw=2, zorder=2)\n",
    "plt.scatter(x, values, s=sizes, marker='s', edgecolors=cols, lw=1.5, facecolors=face_colors, zorder=2)\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.xlim(0.7, ntasks + 0.2)\n",
    "ax.set_xlabel('Task')\n",
    "ax.set_ylabel(r'${AA}_{t}$')\n",
    "plt.legend(r\"$d$-Simplex-HOC\")\n",
    "plt.ylim(27, 73)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
